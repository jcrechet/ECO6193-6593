{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ECO6193/6593 - Assignment 1/Devoir 1. Solutions for part 2 (unemployment cyclical decomposition based on LFS unemployment duration data for Canada, 1976)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import raw data collected from Cansim (LFS population estimates). Series: - labour force (v2062810); unemployment (v2062814); unemployment 1 to 4 weeks (v1078667742). All series are in person units and seasonally adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show directory path\n",
    "os.getcwd()\n",
    "\n",
    "# import local files for raw data\n",
    "df = pd.read_csv('cansim_data.txt', header = 9, index_col=0, parse_dates=True, sep = ',', names = ['l_t', 'u_t', 'us_t'])\n",
    "\n",
    "# compute unemployment rate\n",
    "df['ur_t'] = df['u_t']/df['l_t']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute monthly transition probabilities using Shimer (2012) method. First, compute $F_t$ the job-finding probability (monthly UE probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job finding probabililty\n",
    "\n",
    "# compute lead of unemployment population\n",
    "df['u_{t+1}'] = df['u_t'].shift(-1)\n",
    "df['us_{t+1}'] = df['us_t'].shift(-1)\n",
    "\n",
    "# compute job finding probability\n",
    "df['F_t'] = 1 - ( df['u_{t+1}'] - df['us_{t+1}'] ) / df['u_t']\n",
    "\n",
    "\n",
    "# job-finding rate\n",
    "df['f_t'] = - np.log(1 - df['F_t'])\n",
    "\n",
    "# keep sample where unemployment duration is not missing\n",
    "df = df.loc[~ df['us_t'].isna() ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $S_t$, the job separation probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function of t to solve for s_t\n",
    "def g(t, s, df):\n",
    "\n",
    "    df = df.loc[df.index == t]\n",
    "\n",
    "    f = df['f_t']\n",
    "    l = df['l_t']\n",
    "    u = df['u_t']\n",
    "    u_lead = df['u_{t+1}']\n",
    "    u_ss = s / (s + f)\n",
    "\n",
    "    return u_lead - u_ss * l + np.exp( -(s+f)  ) * (u - u_ss * l) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial variable\n",
    "df['s_t'] = np.nan\n",
    "\n",
    "# diagnostic\n",
    "df['obj'] = np.nan\n",
    "\n",
    "# iterate over time to find s_t\n",
    "for t in df.index[:-1]:\n",
    "\n",
    "    # show date\n",
    "    print(t)\n",
    "    \n",
    "    # initial guess\n",
    "    s0 = 0.03\n",
    "\n",
    "    # objective function\n",
    "    f = lambda s: g(t, s, df)\n",
    "\n",
    "    # evaluate objective function\n",
    "    print(f(s0))\n",
    "\n",
    "    # solve for s_t\n",
    "    s_t = sp.optimize.fsolve(f, s0)\n",
    "\n",
    "    # show solution objective\n",
    "    print([s_t, f(s_t)])\n",
    "\n",
    "    # stack s_t in dataframe\n",
    "    df.loc[df.index == t, 's_t'] = s_t\n",
    "    df.loc[df.index == t, 'obj'] = f(s_t)\n",
    "\n",
    "# compute the job separation probability\n",
    "df['S_t'] = 1 - np.exp( - df['s_t'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute cyclical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute quarterly averages\n",
    "dfq = df[ ['ur_t', 'S_t', 's_t', 'F_t', 'f_t'] ].resample('Q').mean()\n",
    "\n",
    "# HP trends\n",
    "import statsmodels.tsa.filters.hp_filter as hp\n",
    "\n",
    "# hp trends\n",
    "dfq['S_t_trend'] = hp.hpfilter(dfq['S_t'], lamb = 1600)[1]\n",
    "dfq['s_t_trend'] = hp.hpfilter(dfq['s_t'], lamb = 1600)[1]\n",
    "dfq['F_t_trend'] = hp.hpfilter(dfq['F_t'], lamb = 1600)[1]\n",
    "dfq['f_t_trend'] = hp.hpfilter(dfq['f_t'], lamb = 1600)[1]\n",
    "\n",
    "# log cyclical components\n",
    "dfq['S_t_cyc'] = np.log( dfq['S_t'] / dfq['S_t_trend'] )\n",
    "dfq['s_t_cyc'] = np.log( dfq['s_t'] / dfq['s_t_trend'] )\n",
    "dfq['F_t_cyc'] = np.log( dfq['F_t'] / dfq['F_t_trend'] )\n",
    "dfq['f_t_cyc'] = np.log( dfq['f_t'] / dfq['f_t_trend'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots: job separation and job finding monthly probabilities (cyclical component)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2, sharex=True, figsize = (10, 6) )\n",
    "\n",
    "axs[0].plot( dfq['S_t_cyc'] )\n",
    "axs[0].grid(True, linestyle = '--')\n",
    "axs[0].set_ylim(-0.4, 0.4 )\n",
    "axs[0].set_title('Monthly Job separation probability (cyclical)')\n",
    "\n",
    "\n",
    "axs[1].plot( dfq['F_t_cyc'] )\n",
    "axs[1].grid(True, linestyle = '--')\n",
    "axs[1].set_ylim(-0.3, 0.3 )\n",
    "axs[1].set_title('Monthly Job finding probability (cyclical)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the actual unemployment rate vs. the steady-state unemployment cyclical component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual unemployment rate\n",
    "ur = dfq['ur_t']  \n",
    "\n",
    "# cyclical component of unemployment rate\n",
    "ur_cyc = np.log( ur / hp.hpfilter(ur, lamb = 1600)[1] )\n",
    "\n",
    "# steady-state\n",
    "ur_ss = dfq['s_t'] / (dfq['s_t'] + dfq['f_t'])\n",
    "\n",
    "# trend (Ã  la Fujita, Ramey (2009))\n",
    "ur_ss_bar = dfq['s_t_trend'] / ( dfq['s_t_trend'] + dfq['f_t_trend'] )\n",
    "\n",
    "# cyclical component of steady-state unemployment rate\n",
    "ur_ss_cyc = np.log( ur_ss / ur_ss_bar )\n",
    "\n",
    "# plot\n",
    "plt.plot(ur_cyc, label = 'Actual unemployment rate')\n",
    "plt.plot(ur_ss_cyc, label = 'Steady-state unemployment rate')\n",
    "\n",
    "# show correlation\n",
    "print('Correlation = ')\n",
    "print( np.corrcoef(ur_cyc, ur_ss_cyc)[0,1] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unemployment decomposition, based on Fujita, Ramey (2009). First, define the variables for components of cyclical unemployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# steady-state unemployment rate\n",
    "u_ss = dfq['s_t'] / (dfq['s_t'] + dfq['f_t'])\n",
    "\n",
    "# steady-state unemployment rate, trend\n",
    "u_ss_bar = dfq['s_t_trend'] / (dfq['s_t_trend'] + dfq['f_t_trend'])\n",
    "\n",
    "# unemployment component\n",
    "dfq['du'] = np.log( u_ss / u_ss_bar )\n",
    "\n",
    "# job separation component\n",
    "dfq['ds'] = (1 - u_ss_bar) * np.log( dfq['s_t'] / dfq['s_t_trend'] )\n",
    "\n",
    "# job finding component\n",
    "dfq['df'] = - (1 - u_ss_bar) * np.log( dfq['f_t'] / dfq['f_t_trend'] )\n",
    "\n",
    "# error term\n",
    "dfq['error'] = dfq['du'] - dfq['ds'] - dfq['df']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance-covariance decomposition. One can define a function that take as argument a Dataframe and return a table with results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cyclical unemployment variance decomposition \n",
    "\n",
    "# define a function to compute variance decomposition given dataframe\n",
    "def u_decomp(dfq):\n",
    "\n",
    "    # First, define Fujita, Ramey variables:\n",
    "\n",
    "    # steady-state unemployment rate\n",
    "    u_ss = dfq['s_t'] / (dfq['s_t'] + dfq['f_t'])\n",
    "\n",
    "    # steady-state unemployment rate, trend\n",
    "    u_ss_bar = dfq['s_t_trend'] / (dfq['s_t_trend'] + dfq['f_t_trend'])\n",
    "\n",
    "    # unemployment component\n",
    "    du = np.log( u_ss / u_ss_bar )\n",
    "\n",
    "    # job separation component\n",
    "    dsr = (1 - u_ss_bar) * np.log( dfq['s_t'] / dfq['s_t_trend'] )\n",
    "\n",
    "    # job finding component\n",
    "    djfr = - (1 - u_ss_bar) * np.log( dfq['f_t'] / dfq['f_t_trend'] )\n",
    "\n",
    "    # error term\n",
    "    err = du - djfr - dsr\n",
    "\n",
    "    # variance-covariance matrix\n",
    "    varcov = np.cov( [du, dsr, djfr, err] )\n",
    "\n",
    "    # compute beta's (variance shares)\n",
    "    beta_jfr = varcov[0, 2] / varcov[0, 0]\n",
    "    beta_sr = varcov[0, 1] / varcov[0, 0]\n",
    "    residual = varcov[0, 3] / varcov[0, 0]\n",
    "    \n",
    "    # build a list\n",
    "    list = [beta_jfr, beta_sr, residual]\n",
    "\n",
    "    # build a table with results\n",
    "    table = pd.DataFrame(list, index = ['beta_jfr', 'beta_sr', 'residual'], columns = ['variance_share'])\n",
    "\n",
    "    return [table, varcov]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the decomposition on the full sample and show the results in a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance decomposition, from 2000 to 2023\n",
    "print('Cyclical unemployment decompositon, from 2000 to 2023:')\n",
    "[tab, varcov] = u_decomp(dfq)\n",
    "tab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same, but using pre-COVID data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data from 2000 to 2019\n",
    "dfq_pre = dfq.loc['2000-01-01':'2019-12-01', :]\n",
    "\n",
    "# variance decomposition, from 2000 to 2019\n",
    "[tab_pre, varcov_pre] = u_decomp(dfq_pre)\n",
    "print('Cyclical unemployment decompositon, from 2000 to 2019:')\n",
    "tab_pre\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
